# About this course

This course is fantastic and definitely worth your time. Here are a few key takeaways:

- Randomness is part of life and part of this course.
- Remember, effort doesn't always translate to progress; focus on the journey, not just the outcome.
- Take the opportunity to learn from your peers. 

## Course

DNN, DL, NLP, CV, ML, NN, TF, CNN, RNN, LSTM, GRU, GAN, DRL

## General

**Instructor**:  Oleg Melnikov

**TA**: Samuel Nathanson (head TA), David Na, Sergey Sviridov, Jonathan Merran.

**Office hours**:  Saturday, 10 am ET (7 am PST) via Zoom

## Textbook

### Required

Hands-On Machine Learning (HOML) with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems (2nd edition). Géron, A. (2019). O'Reilly Media ISBN-13: 978-1492032649

### Optional (free):

1. Deep learning, Ian Goodfellow, et. al. 2016. MIT Press
2. Pattern recognition and machine learning. Svensén, M. and Bishop, C.M., 2007.
3. Dive into deep learning. Zhang, A., Lipton, Z.C., Li, M. and Smola, A.J., 2021. arXiv:2106.11342.
4. Foundations of machine learning. Mohri, M., Rostamizadeh, A. and Talwalkar, A., 2018. MIT press.
5. An introduction to statistical learning (Vol. 112, p. 18). James, G., Witten, D., Hastie, T. and Tibshirani, R., 2013. New York: Springer.
6. The elements of statistical learning (Vol. 1, No. 10). Friedman, J., Hastie, T. and Tibshirani, R., 2001. New York: Springer series in statistics. 
7. Applications of deep neural networks. Heaton, J., 2020. arXiv:2009.05673.

### Prerequisite Material:

1. Mathematics for machine learning. Deisenroth, M.P., Faisal, A.A. and Ong, C.S., 2020. Cambridge University Press. 
2. The Matrix Cookbook. Petersen, K.B. and Pedersen, M.S., 2008. Technical University of Denmark, 7(15), p.510.
3. Beginner's Guide to Python and Python Tutorial. Python.org

## Grade

1. 30%: Assignments, incl. peer assessments
2. 30%: Auto-graded quizzes
3. 10%: Participation discussion forums, incl. publication discussions
4. 30%: Final project and presentation (e.g. Kaggle competition). Project might be done in stages.

# Course Topics

1. HOML Ch.1-2: Machine Learning Fundamentals
2. HOML 3-4: Classication and Regression
3. HOML 6-7: Decision Trees and Ensembles
4. HOML 8-9: Dimension Reduction, Unsupervised Learning 
5. HOML 10: Articial Neural Network (ANN) with Keras
6. HOML 11: Training a Deep Neural Network (DNN)

7. HOML 12: Custom Models and Training with TensorFlow (TF)
8. HOML 13: Load and Preprocess Data with TF

9. HOML 14: Deep Computer Vision (CV) and Convolutional Neural Networks (CNN)
10. HOML 15: Process Sequences Using Recurrent Neural Networks (RNN) and CNNs
11. HOML 16: NLP with RNNs and Attention
12. HOML 17: Representation Learning and Generative Adversarial Networks (GAN) 
13. HOML 18: Reinforcement Learning
14. HOML 19: Train and Deploy Scale

## Week 01

## Week 04

[Bagging和Boosting的区别](https://cloud.tencent.com/developer/news/393218)

# Programming Assignments

# Tips

- Feature Engineering

  - EDA: 
  - imBalance: Sub-sampling, SMOTE. 
  - Outlier: DBSCAN. Outlier (STD, stats.boxcox)
  - Feature augmentation. Data augmentation
  - Feature Selection: Poly + PCA
  - Feature Importance. 

- Model Selection. 

  - Find the right tool/package for the problem. 
  - Try different type of models

- Tuning Model

  - Cross validation, CV variance. 

- Ideas. Domain knowledge. 

- Check the gap between prediction and real label, and adjust

  

- Coding

- Use Dictionary to manages the parameters

- 20 lines per function

- Unit test.

- Understand the problem and the benefits gained in selecting a particular strategy or tools. Focus on the trade offs. Consider Pro and cons among many different factors, such as: 

- [Feynman Technique](https://en.wikipedia.org/wiki/Feynman_Technique)
  - **Concept**: Choose the subject to study
  - **Explain**: Pretend to explain it to a child
  - **Fill**: Fill in gaps in understanding exposed in step 2 by returning to the sources
  - **Simplify**: Simplify the explanation

- Discussion: Critical thinking

# Paper and article
